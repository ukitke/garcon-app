import { Pool, PoolClient } from 'pg';\nimport { EventEmitter } from 'events';\nimport { performance } from 'perf_hooks';\n\ninterface QueryStats {\n  query: string;\n  executionTime: number;\n  rowCount: number;\n  timestamp: Date;\n  params?: any[];\n}\n\ninterface ConnectionPoolStats {\n  totalConnections: number;\n  idleConnections: number;\n  waitingClients: number;\n  maxConnections: number;\n}\n\ninterface DatabaseMetrics {\n  queryStats: QueryStats[];\n  slowQueries: QueryStats[];\n  connectionStats: ConnectionPoolStats;\n  cacheHitRatio: number;\n  indexUsage: any[];\n  tableStats: any[];\n}\n\nclass DatabaseOptimizationService extends EventEmitter {\n  private pool: Pool;\n  private queryStats: QueryStats[] = [];\n  private slowQueryThreshold: number = 1000; // 1 second\n  private maxStatsHistory: number = 1000;\n  private optimizationRules: Map<string, Function> = new Map();\n  private indexSuggestions: Map<string, string[]> = new Map();\n\n  constructor(pool: Pool) {\n    super();\n    this.pool = pool;\n    this.setupOptimizationRules();\n    this.startPerformanceMonitoring();\n  }\n\n  private setupOptimizationRules() {\n    // Rule: Detect missing indexes on frequently queried columns\n    this.optimizationRules.set('missing_indexes', (stats: QueryStats[]) => {\n      const suggestions: string[] = [];\n      const frequentWhereColumns = new Map<string, number>();\n      \n      stats.forEach(stat => {\n        const whereMatch = stat.query.match(/WHERE\\s+(\\w+)\\s*=/gi);\n        if (whereMatch) {\n          whereMatch.forEach(match => {\n            const column = match.replace(/WHERE\\s+/i, '').replace(/\\s*=.*/, '');\n            frequentWhereColumns.set(column, (frequentWhereColumns.get(column) || 0) + 1);\n          });\n        }\n      });\n      \n      frequentWhereColumns.forEach((count, column) => {\n        if (count > 10) { // Frequently used column\n          suggestions.push(`Consider adding index on column: ${column}`);\n        }\n      });\n      \n      return suggestions;\n    });\n\n    // Rule: Detect N+1 query problems\n    this.optimizationRules.set('n_plus_one', (stats: QueryStats[]) => {\n      const suggestions: string[] = [];\n      const queryPatterns = new Map<string, number>();\n      \n      stats.forEach(stat => {\n        // Normalize query by removing specific values\n        const normalizedQuery = stat.query.replace(/\\$\\d+/g, '?').replace(/\\d+/g, 'N');\n        queryPatterns.set(normalizedQuery, (queryPatterns.get(normalizedQuery) || 0) + 1);\n      });\n      \n      queryPatterns.forEach((count, pattern) => {\n        if (count > 20 && pattern.includes('SELECT') && pattern.includes('WHERE')) {\n          suggestions.push(`Potential N+1 query detected: ${pattern.substring(0, 100)}...`);\n        }\n      });\n      \n      return suggestions;\n    });\n\n    // Rule: Detect inefficient LIKE queries\n    this.optimizationRules.set('inefficient_like', (stats: QueryStats[]) => {\n      const suggestions: string[] = [];\n      \n      stats.forEach(stat => {\n        if (stat.query.includes('LIKE') && stat.executionTime > this.slowQueryThreshold) {\n          if (stat.query.includes(\"LIKE '%\")) {\n            suggestions.push('Avoid leading wildcards in LIKE queries for better performance');\n          }\n        }\n      });\n      \n      return [...new Set(suggestions)];\n    });\n  }\n\n  private startPerformanceMonitoring() {\n    // Monitor every 5 minutes\n    setInterval(async () => {\n      await this.collectDatabaseMetrics();\n      await this.analyzePerformance();\n    }, 5 * 60 * 1000);\n\n    // Clean up old stats every hour\n    setInterval(() => {\n      this.cleanupOldStats();\n    }, 60 * 60 * 1000);\n  }\n\n  public async executeQuery(query: string, params?: any[]): Promise<any> {\n    const startTime = performance.now();\n    let client: PoolClient | null = null;\n    \n    try {\n      client = await this.pool.connect();\n      const result = await client.query(query, params);\n      const executionTime = performance.now() - startTime;\n      \n      // Record query statistics\n      const queryStats: QueryStats = {\n        query: this.sanitizeQuery(query),\n        executionTime,\n        rowCount: result.rowCount || 0,\n        timestamp: new Date(),\n        params: params ? this.sanitizeParams(params) : undefined,\n      };\n      \n      this.recordQueryStats(queryStats);\n      \n      // Emit event for slow queries\n      if (executionTime > this.slowQueryThreshold) {\n        this.emit('slowQuery', queryStats);\n      }\n      \n      return result;\n    } catch (error) {\n      const executionTime = performance.now() - startTime;\n      \n      // Record failed query\n      this.recordQueryStats({\n        query: this.sanitizeQuery(query),\n        executionTime,\n        rowCount: 0,\n        timestamp: new Date(),\n        params: params ? this.sanitizeParams(params) : undefined,\n      });\n      \n      this.emit('queryError', { query, error, executionTime });\n      throw error;\n    } finally {\n      if (client) {\n        client.release();\n      }\n    }\n  }\n\n  private sanitizeQuery(query: string): string {\n    // Remove sensitive data from query for logging\n    return query\n      .replace(/password\\s*=\\s*'[^']*'/gi, \"password = '[REDACTED]'\")\n      .replace(/email\\s*=\\s*'[^']*'/gi, \"email = '[REDACTED]'\")\n      .substring(0, 500); // Limit query length\n  }\n\n  private sanitizeParams(params: any[]): any[] {\n    // Remove sensitive parameters\n    return params.map((param, index) => {\n      if (typeof param === 'string' && param.includes('@')) {\n        return '[EMAIL_REDACTED]';\n      }\n      if (typeof param === 'string' && param.length > 50) {\n        return '[LONG_STRING_REDACTED]';\n      }\n      return param;\n    });\n  }\n\n  private recordQueryStats(stats: QueryStats) {\n    this.queryStats.push(stats);\n    \n    // Keep only recent stats\n    if (this.queryStats.length > this.maxStatsHistory) {\n      this.queryStats = this.queryStats.slice(-this.maxStatsHistory);\n    }\n  }\n\n  private cleanupOldStats() {\n    const oneHourAgo = new Date(Date.now() - 60 * 60 * 1000);\n    this.queryStats = this.queryStats.filter(stat => stat.timestamp > oneHourAgo);\n  }\n\n  public async collectDatabaseMetrics(): Promise<DatabaseMetrics> {\n    try {\n      const [connectionStats, cacheStats, indexUsage, tableStats] = await Promise.all([\n        this.getConnectionStats(),\n        this.getCacheHitRatio(),\n        this.getIndexUsage(),\n        this.getTableStats(),\n      ]);\n\n      const slowQueries = this.queryStats.filter(stat => stat.executionTime > this.slowQueryThreshold);\n\n      return {\n        queryStats: this.queryStats.slice(-100), // Last 100 queries\n        slowQueries,\n        connectionStats,\n        cacheHitRatio: cacheStats,\n        indexUsage,\n        tableStats,\n      };\n    } catch (error) {\n      console.error('Failed to collect database metrics:', error);\n      throw error;\n    }\n  }\n\n  private async getConnectionStats(): Promise<ConnectionPoolStats> {\n    return {\n      totalConnections: this.pool.totalCount,\n      idleConnections: this.pool.idleCount,\n      waitingClients: this.pool.waitingCount,\n      maxConnections: this.pool.options.max || 20,\n    };\n  }\n\n  private async getCacheHitRatio(): Promise<number> {\n    try {\n      const result = await this.pool.query(`\n        SELECT \n          sum(heap_blks_hit) as heap_hit,\n          sum(heap_blks_read) as heap_read,\n          sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) as ratio\n        FROM pg_statio_user_tables;\n      `);\n      \n      return result.rows[0]?.ratio || 0;\n    } catch (error) {\n      console.error('Failed to get cache hit ratio:', error);\n      return 0;\n    }\n  }\n\n  private async getIndexUsage(): Promise<any[]> {\n    try {\n      const result = await this.pool.query(`\n        SELECT \n          schemaname,\n          tablename,\n          indexname,\n          idx_tup_read,\n          idx_tup_fetch,\n          idx_scan\n        FROM pg_stat_user_indexes \n        ORDER BY idx_scan DESC\n        LIMIT 20;\n      `);\n      \n      return result.rows;\n    } catch (error) {\n      console.error('Failed to get index usage:', error);\n      return [];\n    }\n  }\n\n  private async getTableStats(): Promise<any[]> {\n    try {\n      const result = await this.pool.query(`\n        SELECT \n          schemaname,\n          tablename,\n          seq_scan,\n          seq_tup_read,\n          idx_scan,\n          idx_tup_fetch,\n          n_tup_ins,\n          n_tup_upd,\n          n_tup_del,\n          n_live_tup,\n          n_dead_tup\n        FROM pg_stat_user_tables \n        ORDER BY seq_scan DESC\n        LIMIT 20;\n      `);\n      \n      return result.rows;\n    } catch (error) {\n      console.error('Failed to get table stats:', error);\n      return [];\n    }\n  }\n\n  public async analyzePerformance(): Promise<string[]> {\n    const suggestions: string[] = [];\n    \n    try {\n      // Run optimization rules\n      for (const [ruleName, ruleFunction] of this.optimizationRules) {\n        try {\n          const ruleSuggestions = ruleFunction(this.queryStats);\n          suggestions.push(...ruleSuggestions);\n        } catch (error) {\n          console.error(`Failed to run optimization rule ${ruleName}:`, error);\n        }\n      }\n\n      // Analyze connection pool usage\n      const connectionStats = await this.getConnectionStats();\n      const poolUtilization = connectionStats.totalConnections / connectionStats.maxConnections;\n      \n      if (poolUtilization > 0.8) {\n        suggestions.push('Connection pool utilization is high (>80%). Consider increasing pool size.');\n      }\n      \n      if (connectionStats.waitingClients > 0) {\n        suggestions.push('Clients are waiting for database connections. Consider optimizing queries or increasing pool size.');\n      }\n\n      // Analyze cache hit ratio\n      const cacheHitRatio = await this.getCacheHitRatio();\n      if (cacheHitRatio < 0.9) {\n        suggestions.push(`Database cache hit ratio is low (${(cacheHitRatio * 100).toFixed(1)}%). Consider increasing shared_buffers.`);\n      }\n\n      // Analyze slow queries\n      const recentSlowQueries = this.queryStats.filter(\n        stat => stat.executionTime > this.slowQueryThreshold && \n                stat.timestamp > new Date(Date.now() - 60 * 60 * 1000)\n      );\n      \n      if (recentSlowQueries.length > 10) {\n        suggestions.push(`${recentSlowQueries.length} slow queries detected in the last hour. Review query performance.`);\n      }\n\n      // Store suggestions for later retrieval\n      if (suggestions.length > 0) {\n        this.emit('optimizationSuggestions', suggestions);\n      }\n\n      return suggestions;\n    } catch (error) {\n      console.error('Failed to analyze performance:', error);\n      return ['Failed to analyze database performance'];\n    }\n  }\n\n  public async createOptimalIndexes(): Promise<string[]> {\n    const createdIndexes: string[] = [];\n    \n    try {\n      // Analyze query patterns to suggest indexes\n      const indexSuggestions = await this.generateIndexSuggestions();\n      \n      for (const [table, columns] of indexSuggestions) {\n        for (const column of columns) {\n          const indexName = `idx_${table}_${column}_auto`;\n          \n          try {\n            // Check if index already exists\n            const existingIndex = await this.pool.query(`\n              SELECT indexname FROM pg_indexes \n              WHERE tablename = $1 AND indexname = $2\n            `, [table, indexName]);\n            \n            if (existingIndex.rows.length === 0) {\n              // Create index concurrently to avoid blocking\n              await this.pool.query(`\n                CREATE INDEX CONCURRENTLY ${indexName} ON ${table} (${column})\n              `);\n              \n              createdIndexes.push(`${indexName} on ${table}(${column})`);\n            }\n          } catch (error) {\n            console.error(`Failed to create index ${indexName}:`, error);\n          }\n        }\n      }\n    } catch (error) {\n      console.error('Failed to create optimal indexes:', error);\n    }\n    \n    return createdIndexes;\n  }\n\n  private async generateIndexSuggestions(): Promise<Map<string, string[]>> {\n    const suggestions = new Map<string, string[]>();\n    \n    // Analyze WHERE clauses in recent queries\n    const recentQueries = this.queryStats.filter(\n      stat => stat.timestamp > new Date(Date.now() - 24 * 60 * 60 * 1000)\n    );\n    \n    const columnUsage = new Map<string, number>();\n    \n    recentQueries.forEach(stat => {\n      // Extract table and column from WHERE clauses\n      const whereMatches = stat.query.match(/FROM\\s+(\\w+).*WHERE\\s+(\\w+)\\s*=/gi);\n      if (whereMatches) {\n        whereMatches.forEach(match => {\n          const tableMatch = match.match(/FROM\\s+(\\w+)/i);\n          const columnMatch = match.match(/WHERE\\s+(\\w+)/i);\n          \n          if (tableMatch && columnMatch) {\n            const table = tableMatch[1];\n            const column = columnMatch[1];\n            const key = `${table}.${column}`;\n            \n            columnUsage.set(key, (columnUsage.get(key) || 0) + 1);\n          }\n        });\n      }\n    });\n    \n    // Suggest indexes for frequently used columns\n    columnUsage.forEach((count, key) => {\n      if (count > 5) { // Used more than 5 times\n        const [table, column] = key.split('.');\n        if (!suggestions.has(table)) {\n          suggestions.set(table, []);\n        }\n        suggestions.get(table)!.push(column);\n      }\n    });\n    \n    return suggestions;\n  }\n\n  public async optimizeQueries(): Promise<string[]> {\n    const optimizations: string[] = [];\n    \n    try {\n      // Update table statistics\n      await this.pool.query('ANALYZE;');\n      optimizations.push('Updated table statistics');\n      \n      // Reindex tables with high dead tuple ratio\n      const tablesNeedingReindex = await this.pool.query(`\n        SELECT \n          schemaname, \n          tablename,\n          n_dead_tup,\n          n_live_tup,\n          n_dead_tup::float / (n_live_tup + n_dead_tup) as dead_ratio\n        FROM pg_stat_user_tables \n        WHERE n_live_tup > 0 \n        AND n_dead_tup::float / (n_live_tup + n_dead_tup) > 0.2\n        ORDER BY dead_ratio DESC;\n      `);\n      \n      for (const table of tablesNeedingReindex.rows) {\n        try {\n          await this.pool.query(`REINDEX TABLE ${table.tablename};`);\n          optimizations.push(`Reindexed table ${table.tablename}`);\n        } catch (error) {\n          console.error(`Failed to reindex table ${table.tablename}:`, error);\n        }\n      }\n      \n      // Vacuum tables with high dead tuple ratio\n      for (const table of tablesNeedingReindex.rows) {\n        try {\n          await this.pool.query(`VACUUM ANALYZE ${table.tablename};`);\n          optimizations.push(`Vacuumed table ${table.tablename}`);\n        } catch (error) {\n          console.error(`Failed to vacuum table ${table.tablename}:`, error);\n        }\n      }\n      \n    } catch (error) {\n      console.error('Failed to optimize queries:', error);\n    }\n    \n    return optimizations;\n  }\n\n  public getSlowQueries(limit: number = 10): QueryStats[] {\n    return this.queryStats\n      .filter(stat => stat.executionTime > this.slowQueryThreshold)\n      .sort((a, b) => b.executionTime - a.executionTime)\n      .slice(0, limit);\n  }\n\n  public getQueryStatsSummary(): any {\n    const totalQueries = this.queryStats.length;\n    const slowQueries = this.queryStats.filter(stat => stat.executionTime > this.slowQueryThreshold).length;\n    const avgExecutionTime = this.queryStats.reduce((sum, stat) => sum + stat.executionTime, 0) / totalQueries;\n    \n    return {\n      totalQueries,\n      slowQueries,\n      slowQueryPercentage: totalQueries > 0 ? (slowQueries / totalQueries) * 100 : 0,\n      avgExecutionTime: avgExecutionTime || 0,\n      maxExecutionTime: Math.max(...this.queryStats.map(stat => stat.executionTime), 0),\n      minExecutionTime: Math.min(...this.queryStats.map(stat => stat.executionTime), 0),\n    };\n  }\n\n  public setSlowQueryThreshold(threshold: number) {\n    this.slowQueryThreshold = threshold;\n  }\n\n  public async healthCheck(): Promise<{ status: string; metrics: any }> {\n    try {\n      const startTime = performance.now();\n      await this.pool.query('SELECT 1');\n      const responseTime = performance.now() - startTime;\n      \n      const metrics = await this.collectDatabaseMetrics();\n      const connectionStats = metrics.connectionStats;\n      \n      const status = {\n        database: 'healthy',\n        responseTime: `${responseTime.toFixed(2)}ms`,\n        connections: `${connectionStats.totalConnections}/${connectionStats.maxConnections}`,\n        cacheHitRatio: `${(metrics.cacheHitRatio * 100).toFixed(1)}%`,\n        slowQueries: metrics.slowQueries.length,\n      };\n      \n      return { status: 'healthy', metrics: status };\n    } catch (error) {\n      return { \n        status: 'unhealthy', \n        metrics: { error: error.message } \n      };\n    }\n  }\n}\n\n// Singleton instance\nlet dbOptimizationServiceInstance: DatabaseOptimizationService;\n\nexport const initializeDatabaseOptimizationService = (pool: Pool): DatabaseOptimizationService => {\n  if (!dbOptimizationServiceInstance) {\n    dbOptimizationServiceInstance = new DatabaseOptimizationService(pool);\n  }\n  return dbOptimizationServiceInstance;\n};\n\nexport const dbOptimizationService = dbOptimizationServiceInstance;\n\nexport default DatabaseOptimizationService;"